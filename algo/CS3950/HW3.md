# T1

## Some Warnings!

**ATTENTION!**

**ATTENTION!**

**ATTENTION!**


I misunderstood the meaning of CHATGPT. Thanks to Yuhao Zhang, I fixed my understanding. So you may just ignore the ABOUT CHATGPT section below and just see my solution.

I will prove later that my solution is the same as CHATGPT in some way.

## About CHATGPT

First, I'm sorry to say that CHATGPT is BS-ing. The counter example comes as follows:

Conside $p = \{1,2,3,4\}$. On first day, the min-heap contains $\{1\}$. On the second day, since $1 \lt 2$, the algorithm pops $1$ from min-heap and insert $2$, claim to have a gain of $1$. Then, on the third day, similar things happens ($3$ pops $2$, claiming gain as $1$). So is the fourth day. After the fourth day, we have only $\{4\}$ in the min-heap. The total gain is $1 + 1 + 1 = 3$.

However, we can do it better. We can buy stock on day $1 , 2$ and sell on day $3$ and $4$. The total gain is $3 + 4 - 1 - 2 = 4$. So the algorithm is not optimal.

> REMARK: The problem of this algorithm is that it doesn't reconsider the element which pops out of the min-heap at all. Some of those elements have poped out other elements to be in the min-heap, so when they are poped, they might be reused some time later.

## My solution

### Dynamic programming

Let $f(i, j)$ be the maximum gain we can get from the first $i$ days with $j$ stocks in hand. Then we have the following recursive formula:

$$
\begin{aligned}
f(i, j) &= \max \{ f(i - 1, j), f(i - 1, j - 1) - p_i ,f(i - 1, j + 1) + p_i \} (j \gt 0) \\
f(i, 0) &= \max \{ f(i - 1, 0), f(i - 1, 1) + p_i \}
\end{aligned}
$$

Specially, we have $f(0, 0) = 0$ and other $f(0, j) = -\infty$.

This trivially holds true, and the time complexity is $\mathcal{O}(n^2)$.

### An improved solution of CHATGPT

The chatgpt is already doing a good job, except it fails to reconsider some elements. We improve it as follows:

- Enumerate the days from $1$ to $n$.

- If the min-heap is empty, insert the stock price of the day.

- If the min-heap is not empty, compare the smallest element $p_j$ in the min-heap with the stock price $p_i$ of the day.

    + If $p_j \ge p_i$, insert $p_i$ into the min-heap.

    + If $p_j \lt p_i$, insert $p_i$ into the min-heap and mark $i$ as sold-out. Then checking $j$.

        * If $j$ is marked as sold-out, just reset $j$ as not sold-out, and keep it in the min-heap.

        * Otherwise, pop $j$ from the min-heap. $j$ will never be used again. We mark it as buy-out.

The only difference is that for those "sold-out" elements, if they are cheaper than the current stock price, they will not be poped out, but just reset to be not sold-out.

It's obivious that the time complexity is $\mathcal{O}(n \log n)$ (since we only insert and pop elements from the min-heap).

The hardest part is to prove the correctness of this algorithm.

#### Notations

Without loss of generality, we assume that the stock prices are distinct.

First, we introduce some notations:

- Choice $c$, where $c_i = \{-1, 0, 1\}$, means the choice of the $i$-th day. $-1$ means sell, $0$ means do nothing, and $1$ means buy.

- $s_i = \sum_{k=1}^i c_k$ is the number of stocks in hand after the $i$-th day. A valid choice must ensure that $s_i \ge 0$ for all $i$.

- If $s_i = 0$, we call day $i$ a zero-stock day.

- Special function $z(i,j)$. If there exists a zero-stock day $k \in [i, j - 1]$, then $z(i,j) = 1$. Otherwise, $z(i,j) = 0$.

- Profit $P(c) = \sum_{i=1}^n -c_i p_i$ is the profit of the choice $c$. This holds true by definition.

#### Observations

We have some intuitive observations:

1. If $\exists i,j, p_i\lt p_j, i \lt j, c_i \in \{-1,0\}, c_j \in \{0,1\}$, then $c$ is not optimal.
2. If $\exists i,j, p_i\gt p_j, i \lt j, c_i \in \{0,1\}, c_j \in \{-1,0\}, z(i,j) = 0$, then $c$ is not optimal.
3. If $c(n) = 1$, then $c$ is not optimal.

If $1$ happens, we can improve $c$ by letting $c' = c$ except that ${c_i}' = c_i + 1$ and ${c_j}' = c_j - 1$. The profit of $c'$ is $P(c') = P(c) - p_i + p_j \gt P(c)$. In addition, the validity of $c'$ is guaranteed since this operation will only make ${s_x}'$ no less than ${s_x}$, where $x \in [1,n]$. So $c'$ is a better choice than $c$. $c$ is not optimal.

$2$ is similar to $1$, except that ${s_x}' = s_x - 1$ for those $x \in [i,j - 1]$, while other $s_x$ remains the same. The validity is challenged, but with the additional condition that $z(i,j) = 0$, which means all ${s_x} \ge 1$ for $x \in [i,j - 1]$. So ${s_x}' \ge 0$ for all $x \in [1,n]$. The validity is guaranteed. So $c$ is not optimal.

$3$ is also trivial, since we may cancel the last buy operation.

We call a choice $c$ a "perfect" choice if it doesn't have those three conditions. We have proved that if a choice is optimal, then it must be a "perfect" choice.

#### Induction

Then, we are going to prove that there's only one "perfect" choice, which is the choice generated by the algorithm.

This trivially holds true for $n = 1$. We assume that it holds true for $n = k$. Then we consider $n = k + 1$.

Suppose $c$ is one of the "perfect" choices for $n = k + 1$

- $c_{k + 1} = 1$, impossible. We will not mark the last day buy-out.

- $c_{k + 1} = 0$. So, $s_k = s_{k + 1} - c_{k + 1} = 0 - 0 = 0$, which means $c$ is also a (and the only one due to the induction hypothesis) "perfect" choice for $n = k$, which is the previous state of our algorithm. Based on the condition $1$, $\forall i \in [1,k], (p_i \ge p_{k+1} \bigvee c_i = 1)$. Since those buy-out days are out of the heap, all those in-heap elements (all non-buy-out element) are no less than $p_{k+1}$. So, our algorithm will just find out the right buy-out days, finding out the right $c$ choice.

- $c_{k + 1} = -1$. Let $m$ be the last zero-stock day before $k + 1$ (we allow $m$ to be $0$). Suppose $x$ is the most costly stock during $[m + 1, k]$ where $c_x \in \{0,1\}$. We construct $c'$ be choice for $n$ which is almost the same as $c$ except that ${c_x}' = {c_x} - 1$. It's easy and routine to verify that $c'$ is also a valid "perfect" choice. Due to our induction hypothesis, $c'$ is the output of our algorithm for $n = k$. And in this case, since $c$ is a "perfect" choice, due to the condition $1$, all the in-heap (non-buy-out) elements before $x$ must be greater than $p_{x}$. Due to condition $2$, so is all elements after $x$ (we utilize the fact that $m$ is the last zero-stock day and $x$ is after $m$, so $z(x,k+1) = 0$). So in $c'$, $x$ is the cheapest stock in-heap, and with the fact that all elements after $x$ is greater than $p_x$, $p_{k+1}$ should be greater than $p_x$. So, our algorithm will try to use $k+1$ to replace $x$. If $x$ is marked as sold-out (${c_x}' = -1$), then $x$ will be reset from sold-out (${c_x} = 0$). If $x$ is not marked as sold-out(${c_x} = 0$), then $x$ will be poped out (${c_x} = -1$). So, in both cases, $c'$ is the output of our algorithm for $n = k + 1$. So, $c$ is the output of our algorithm for $n = k + 1$.

In summary, for all cases, $c$ is the output of our algorithm for $n = k + 1$. 

However, our algorithm is deterministic, so the only "perfect" choice is the output of our algorithm.

Also, we have proved that any best choice must be a "perfect" choice, but the output of our algorithm is the only "perfect" choice. So the output of our algorithm is the only best choice (based on our assumption that the stock prices are distinct).

If stock prices are not distinct, the proof process is similar, and it's too long to write again here...

<!-- ### Some comments -->

<!-- The core algorithm only took me about $10 \text{min}$. It is easy to be observed with the hint of the given CHATGPT algorithm. However, the correctness of this algorithm is lunatic to prove. I even write a small program to verify the correctness of this algorithm. It did pass all the sample tests. But I still could not prove it out. -->

<!-- The final idea caught me after three hell-like hours. Are you serious? -->

## End proof

Finally, I'm going to prove that my solution is equal to that of CHATGPT.

First, the min-element in min-heap must be identical in my algorithm and CHATGPT's, except those sold-out have an extra backup in CHATGPT's min-heap. This can be proved by induction.

It holds true when $n = 1$.

If holds true for $n = k$, then for $n = k + 1$, case analysis:

- min element $p_x$ no less than current $p_{k+1}$, so both algorithm simply insert $k + 1$ as unsold. So it still holds true in $n = k + 1$.

- min element $p_x$ less than $p_{k+1}$. Then $p_{k+1}$ will be marked as sold-out and has an additional backup.

    + If the $p_x$ is sold-out, in our algorithm, we will simply reset $p_x$ from sold-out. And in CHATGPT's algorithm, it will remove exactly one backup, leaving behind one another in the min-heap (due to induction hypothesis). The new heap still satisfies the assumption, so induction still holds.

    + If otherwise, our algorithm will pop it out of heap and mark as buy-out. In CHATGPT's algorithm, it will pop out the only backup (due to induction hypothesis) from the heap. The new heap still satisfies the assumption, so induction still holds.

Consequently, by induction, we can trivially see that both algorithm choose the same elements and output the same answer. Since we have proved that our algorithm is the best, so is CHATGPT!


## Apology

Sorry for a twisted proof which may be far different from standard answer.

I'm too exhausted to write as perfect a proof as the proof above. I'm mad after 3 hours spent on this problem due to the bloody misundestanding.....

Special thanks to Yuhao Zhang !

# T2

If the carry process of an addition happens $x$ times in the addition process of $y + 1$, then it's trivial to see that the lowest $x$ bits of $y$ are all $1$, and the $(x+1)$-th bit is $0$. After the addition, the lowest $x$ bits of $y$ are all $0$, and the $(x+1)$-th bit is $1$, while the higher bits are unchanged. So there are exactly $x + 1$ bits (the lowest $x+1$ bits) flipped when we add $1$ to $y$, which indicates the addition cost is $x + 1$ operation.

If we define $C(y)$ as the number of bits of $y$ that are $1$, then it's trivial to see that $C(y + 1) = C(y) + 1 - x$ (due to the fact that $1$ bit is flipped to $1$ and $x$ bits are flipped to $0$). It means that $\Delta C = 1 - x$.

So we may let the potential function be $f(y) = C(y)$. The cost of an operation is $x + 1 = 2 - \Delta C$. Also, the potential function is always non-negative, and can grow at most $1$ in each operation. So we can claim that the amortized cost is $\mathcal{O}(1)$ using the potential function $f(y) = C(y)$.

# T3

## (a)

If the assertion is not true, we may assume that there exists two maximal independent sets $A$ and $B$ such that $|A| \lt |B|$. By exchange property, there exists $x \in B - A$ such that $A + \{x\} \in \mathcal{I}$. Then, there exists a set $C = A + \{x\}$ such that $A \subsetneq C$, which contradicts the assumption that $A$ is maximal.

## (b)

<!-- 
Let G = (V, E) be a simple undirected graph. Let M = (E, S) where S = {F ⊆ E | F does not contain a cycle}. Prove that M is a matroid. What are the maximal sets of this matroid?
 -->

Let's prove that $M = (E, \mathcal{S})$ satisfies the 2 properties of matroid:

First, if $A \in \mathcal{S}$, then for any $B \subseteq A$, since subgraph $A$ does not contains a cycle, the subgraph of subgraph $A$, $B$ should never contain a cycle either (I think this is too trivial. If $B$ contains a cycle with edges $\{e_1,\cdots,e_k\}$, then since $B \subseteq A$, $A$ should contains edges $\{e_1,\cdots,e_k\}$ too, which means $A$ contains a cycle, which contradicts the fact that $A \in \mathcal{S}$ a.k.a $A$ has no cycle).

Second, if $|A| \lt |B|$, consider the connected blocks in $A$. We may divide $A$ into connected blocks $\{V_1, \cdots, V_n\}$. Since there's no cycle in graph $A$, based on some lemmas taught in Combinatorics last semester (a connected block $|V|$ should contain at least $|V| - 1$ edges ; an acyclic graph with vertices $V$ should contain at most $|V| - 1 edges; a connected block $|V| with exactly $|V| - 1$ edges is a tree), we may find that each block is a tree, so $|A| = (|V_1| - 1) + \cdots + (|V_n| - 1)$.

Consider those blocks in $B$. In block $V_1$, since $B$ is acyclic, $B$ has at most $|V_1| - 1$ inter-block-$V_1$ edges. The same is the case with $V_2 \cdots, V_n$. So, in $B$, there are at most $(|V_1| - 1) + \cdots + (|V_n| - 1) = |A|$ inter-block edges (the block is based on $A$). However, $|B| \gt |A|$, so there must exists an intra-block edge $x$ for $B$. After adding this intra-block edge to $A$, we reduce the block number of $A$ by $1$, but we do not bring cycles since the edge is intra-block (between blocks). So, $A + \{x\} \in \mathcal{S}$.

Based on the proof above, we can claim now that $\mathcal{S}$ is a matroid.

Then we are going to explore all the maximals of $\mathcal{S}$. 

Suppose $(V,E)$ is composed of connected, disjoint subgraphs $(V_1,E_1), \cdots, (V_n,E_n)$. Based on the lemma in Combinatorics (an acyclic graph with vertices $V$ should contain at most $|V| - 1$ edges), the size of maximal should not exceed $(|V_1| - 1) + \cdots + (|V_n| - 1)$.

For each connected component, there must exist at least one spanning tree. Suppose there are $T_1, \cdots T_n$ for those subgraphs. Then, it's easy to observe that $T = T_1 + \cdots + T_n$ is an acyclic subgraph of $(V,E)$, so it is an element of $\mathcal{S}$. Also, $|T| = (|V_1| - 1) + \cdots + (|V_n| - 1)$, which is maximal available size. Due to (a), the maximal's size is unique, so we may claim that each maximal has size $(|V_1| - 1) + \cdots + (|V_n| - 1)$.

Since, in each disjoint subgraph $(V_i, E_i)$, an element $M$ can contains at most $|V_i| - 1$ edges, so $|M| \le (|V_1| - 1) + \cdots + (|V_n| - 1)$. The equality holds when $M$ has exactly $|V_i| - 1$ edges in each disjoint subgraph $(V_i, E_i)$.

So, these maximals are sets which is composed of exactly one spanning tree in each disjoint subgraph $(V_i, E_i)$.

## (c)

From now on, we abbreviate "a maximal independent set with maximal weight" to "maximal".

Suppose $C$ is a maximal, which does not contain $x$ (if no such, we have already found a required maximal containing $x$, since there's finite independent set and such maximal must exist).

Then let $S_1 = \{x\} \in \mathcal{I}$. If $|S_i| \lt |C|$, using exchange property, we can construct $S_{i + 1} = S_i + {y}, y \in C$ with the property $S_{i+1} \mathcal{I}$.

Consider $D = S_{|C|}$, which has exactly the same size with $C$. Due to the construction process above, it should have exactly $1$ different element from $C$. Suppose that element in $C$ is $y$, which means $D - \{x\} = C - \{y\}$. So $w(D) - w(C) = w(x) - w(y)$

By the guarantee of hereditary property , $\{y\} \in \mathcal{I}$. However, in the first round, $x$ is chosen, which means for any $z \in U$, if $\{z\} in \mathcal{I}$, $w(x)$ must be no less than $w(z)$. So, we may draw the conclusion that $w(x) \ge w(y)$. Consequently, $w(D) - w(C) = w(x) - w(y) \ge 0$. Since $C$ is a maximal, which means $w(D) \le w(C)$, we can find that $w(D) = w(C)$, which means $D$ is also a maximal.

## (d)

We may prove by induction that the algorithm can successfully find max-weight set in size $1,2,\cdots.$ during its process (Explanation: when the size of $S$ is $k$, $S$ is one of the maximals in size $k$).

From now on, we abbreviate "a independent set in size $k$ with maximal weight" to "maximal in size $k$".

When $n = 1$, it's trivial. (Based on the nature of algorithm; which is informally proved in last paragraph in (c))

If this holds true for $n = k$, consider the case when $n = k + 1$.

Suppose $C$ is a maximal in size $k + 1$. Let $A_k$ be the size-$k$-stage $S$ in the algorithm, and $A_{k+1}$ for size $k + 1$. Suppose that our smart algorithm chose element $x$ in this round.

Since $|A_k| = k \lt k + 1 = |C|$, so there must exists $y \in |C|$ such that $A_k + \{y\} \in \mathcal{I}$. Consider $w(A_k + \{y\}) - w(C) = w(A_k) - w(C - \{y\})$. By induction hypothesis, $A_k$ is a maximal in size $k$, which means $w(A_k) \ge w(C - \{y\})$. So, $w(A_k + \{y\}) \ge w(C)$.

Then consider $w(A_{k+1}) - w(A_k + \{y\}) = w(x) - w(y)$. First, if $w(y) \gt w(x)$, it must be listed before $x$ in the algorithm. Suppose $y$ is consider when $S = A_{l}$. Since $y \notin A_{l}$, we have $A_{l} + y \notin \mathcal{I}$ (otherwise, we will choose $y$ in that round). However, $A_{l} + \{y\} \subseteq A_{k} + \{y\} \in \mathcal{I}$, which means $A_{l} + y \in \mathcal{I}$. A contradiction! So $w(x) \ge w(y)$, which means $w(A_{k+1}) \ge w(A_k + \{y\})$.

To sum up, we have $w(A_{k+1}) \ge w(A_k + \{y\}) \ge w(C)$, which means our algorithm finds the maximal in size $k + 1$.

By induction, when our algorithm halts, it output a set $S$, which is a maximal in size $S$. However, we still needs prove it is maximal independent set. Luckily, our algorithm only halt when there can be no element to add to $S$. So if there exists $D \in \mathcal{I}$, where $S \subsetneq D$, then let $v \in D - S$. Using $2$ properties, $S + \{v\} \in \mathcal{I}$, which means $v$ can still be added to $S$. That contradicts the stopping criteria of our algorithm!

So, our algorithm can only halt when it is maximal independent set, and using the conclusion of induction, it is also the max-weighted.

## (e)

We define the set $\mathcal{L} = \{ \ W \subseteq U \ | \text{ vectors in }W \text{ are linear independent }\}$

First, we will prove that $(U, \mathcal{L})$ is a matroid.

- hereditary property: If $W \in \mathcal{L}$, then the vectors in $W$ are linear independent. If $V \subseteq W$, then the vectors in $V$ are linear independent too (of course). So $V \in \mathcal{L}$

- exchange property: If $V, W \in \mathcal{L}$ and $|V| \lt |W|$. This means $rank(V) = |V| \lt |W| = rank(W)$. If every vector in $W$ can be expressed as a linear combination of vectors in $V$, then $rank(W) \le rank(V)$, which contradicts $rank(V) \lt rank(W)$. So there must exist a vector $x$ in $W$ which cannot be expressed as a linear combination of vectors in $V$. So, $V + \{x\} \in \mathcal{L}$.

Then, we are going to find the maximal of $\mathcal{L}$.

We design the algorithm as below:

- Let $S = \emptyset$.
- For each $x \in U$ in descending order of weight.
    + If $S + \{x\} \in \mathcal{L}$, then $S = S + \{x\}$.
    + Otherwise, do nothing.
    + If $|S| = n$, then halt.

The correctness is guaranteed by (d).

When judging whether $\{x\}$ can be added to $S$, we just need to check whether $x$ can be expressed as a linear combination of vectors in $S$. To make this faster, we may maintain an orthonormal basis $B$ of $S$ (just as Gram-Schmidt process). With the orthonormal basis, we can easily check in this way:

- First, project $x$ to each vector $y_i$ in $B$ by dot product. It takes $\mathcal{O}(kn)$ time.
- Then subtract the projection from $x$. It takes $\mathcal{O}(kn)$ time.
- Finally, check the remaining vector $r$. If it is zero, then $x$ can be expressed as a linear combination of vectors in $S$.
- Otherwise, add $\frac{r}{\|r\|}$ to $B$, add $x$ to $S$.

Based on Gram-Schmidt process, we may claim that the process above must be correct. Since $k \le n$, the time complexity is $m \cdot O(n^2) = O(mn^2)$.

# T4

Time distribution (Thinking + Writing):

- T1: $180\text{min} + 30\text{min}$

- T2: $5\text{min} + 5\text{min}$

- T3: $20\text{min} + 80\text{min}$

Difficulty: $5/5$.

Comment: Very hard greedy problem. Make my brain spin.

Collaborators: Yuhao Zhang
