# 0508 Notes + Review

## Some review

Given $$(\Omega, \mathcal{F}, P)$$, a sequence of random variables $X_n$.

### Convergence

**Almost sure convergence** (几乎处处收敛): $X_n \to X$ a.s. if $P(\{\omega \in \Omega: X_n(\omega) \to X(\omega)\}) = 1$. (Denoted as $X_n \xrightarrow{a.s} X$)

**Convergence in probability**(按概率收敛) : $X_n \to X$ in probability if for all $\epsilon > 0$, $P(|X_n - X| > \epsilon) \to 0$ as $n \to \infty$. (Denoted as $X_n \xrightarrow{P} X$)

**Convergence in distribution**(按分布收敛): $X_n \to X$ in distribution if $F_{X_n}(x) \to F_X(x)$ for all $x$ where $F_X$ is the CDF(Cumulative Distribution Function; 分布函数) of $X$ and $F_X$ is continuous at $x$. (Denoted as $X_n \xrightarrow{D} X$)

### Some properties of convergence

- $$X_n \xrightarrow{a.s} X \Rightarrow X_n \xrightarrow{P} X$$
- $$X_n \xrightarrow{P} X \Rightarrow X_n \xrightarrow{D} X$$
- $$X_n \xrightarrow{a.s} X \Leftrightarrow \forall \epsilon > 0, P(\limsup_{n \to \infty} |X_n - X| > \epsilon) = 0$$
- $$X_n \xrightarrow{P} X \Leftrightarrow \forall {X_{n_k}} \exists X_{n_{k_j}} \text{ s.t. } X_{n_{k_j}} \xrightarrow{a.s} X$$

### Expectation

1. Non-negative random variables. Exists a sequence of non-negative simple functions $X_n \uparrow X$. Define $E[X] = \lim_{n \to \infty} E[X_n]$.
2. General random variables. $E[X] = E[X^+] - E[X^-]$ where $X^+ = \max(X, 0)$ and $X^- = \max(-X, 0)$. (Require at least one of them to be finite)(If both of them are finite, we claim that $E[X]$ is integrable).
3. Linearity of expectation. $E[aX + bY] = aE[X] + bE[Y]$.
4. If $X <=_{a.s} Y$, then $E[X] \leq E[Y]$.
5. If $N \in \mathcal{F}$ where $P(N) = 0$, then $E[X1_N] = 0$.

### Fatou's Lemma

$E[X_n]$ exist. If $\exist \text{ r.v } Y \text{ s.t. } X_n \geq_{a.s.} Y$ and $E[Y-] \lt \infty$, then $E(\liminf_{n \to \infty} X_n) \leq \liminf_{n \to \infty} E[X_n]$.

Similarly, we may have $E(\limsup_{n \to \infty} X_n) \geq \limsup_{n \to \infty} E[X_n]$.

### Control Convergence

$$X_n \xrightarrow{P} X, |X_n| \lt_{P} Y, E[Y] \lt \infty \Rightarrow E[X_n] \to E[X]$$

**Proof:**

First, we may prove the version of $a.s.$ convergence. Then we may use Fatou's Lemma to prove that case.

Applying fatou's lemma, we have $E(\liminf_{n \to \infty} X_n) \leq \liminf_{n \to \infty} E[X_n]$ and $E[\limsup_{n \to \infty} X_n] \geq \limsup_{n \to \infty} E[X_n]$. Since $\lim X_n = X$, we have $E[X] = E[\lim X_n] = \lim E[X_n]$.

Then, we may prove by using discriminant and the property that $$X_n \xrightarrow{P} X \Leftrightarrow \forall {X_{n_k}} \exists X_{n_{k_j}} \text{ s.t. } X_{n_{k_j}} \xrightarrow{a.s} X$$.

## Today's notes

### Cauchy-Schwarz Inequality

$$E[XY] \leq \sqrt{E[X^2]E[Y^2]}$$

Proof: Consider $E[X - tY]$ for some $t \in \mathbb{R}$. Then we have $E[(X - tY)^2] \geq 0$, which gives us $E[X^2] - 2tE[XY] + t^2E[Y^2] \geq 0$. Since this holds true for all $t$, the discriminant must be non-positive, which gives us the inequality.

### Holder's Inequality

Let $p, q > 1$ be conjugate exponents, i.e. $\frac{1}{p} + \frac{1}{q} = 1$. Then for any $x, y \geq 0$, we have:

$$E[XY] \leq \frac{1}{p}E[X^p] + \frac{1}{q}E[Y^q]$$

Proof: We have Young's Inequality, which states that for any $a, b \geq 0$, we have $ab \leq \frac{a^p}{p} + \frac{b^q}{q}$. Let $a = \frac{X}{(E[X^p])^{1/p}}$ and $b = \frac{Y}{(E[Y^q])^{1/q}}$. Then we have it.

> Special case: $E[X] = 0$, but in that case $X = 0, a.s.$

## Chebyshev's Inequality

$$ \forall \epsilon > 0, P(|X - E[X]| \geq \epsilon) \leq \frac{D[X]}{\epsilon^2}$$
